{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*JJ McCauley*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification on the Breast Cancer Dataset\n",
    "### Optimizing a Baseline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]] \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "Baseline score for nbc_model1: 0.9415204678362573\n"
     ]
    }
   ],
   "source": [
    "''' Using Naive Bayes Classifier as Baseline, Loading Dataset, & Importing necessary dependencies '''\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Loading in data and splitting\n",
    "loaded_bc_data = load_breast_cancer()\n",
    "X = loaded_bc_data.data\n",
    "y = loaded_bc_data.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=42)\n",
    "\n",
    "# Printing Num of feautes for hyperparameter tuning\n",
    "print(X.shape[1]) \n",
    "\n",
    "# Printing Loaded Data to see how data is represented\n",
    "print(X, \"\\n\", y)  # Data is standardized and targets are 0, 1, so no modification is needed\n",
    "\n",
    "# Using Naive Bayes Classifier as accuracy baseline\n",
    "nbc_model1 = GaussianNB()\n",
    "nbc_model1.fit(x_train, y_train)\n",
    "nbc_model1_y_pred = nbc_model1.predict(x_test)\n",
    "print(f\"Baseline score for nbc_model1: {nbc_model1.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Defining Early Stopping Callback '''\n",
    "# Defining an Early Stopping Function (credit to Logan Kelsch for the idea)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',  # Monitor Validation Accuracy\n",
    "    patience=12,             # Wait 12 Epochs for Improvement\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.4743 - loss: 22.5972 - val_accuracy: 0.9357 - val_loss: 0.2067\n",
      "Epoch 2/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7378 - loss: 1.2829 - val_accuracy: 0.9123 - val_loss: 0.5786\n",
      "Epoch 3/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8539 - loss: 0.9781 - val_accuracy: 0.9474 - val_loss: 0.2675\n",
      "Epoch 4/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8973 - loss: 0.5685 - val_accuracy: 0.9474 - val_loss: 0.1733\n",
      "Epoch 5/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.3764 - val_accuracy: 0.9415 - val_loss: 0.1724\n",
      "Epoch 6/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8911 - loss: 0.3031 - val_accuracy: 0.9357 - val_loss: 0.2121\n",
      "Epoch 7/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9205 - loss: 0.2581 - val_accuracy: 0.8070 - val_loss: 0.4145\n",
      "Epoch 8/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8280 - loss: 0.5060 - val_accuracy: 0.9474 - val_loss: 0.1387\n",
      "Epoch 9/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 0.2563 - val_accuracy: 0.9474 - val_loss: 0.1801\n",
      "Epoch 10/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8999 - loss: 0.2685 - val_accuracy: 0.9298 - val_loss: 0.1725\n",
      "Epoch 11/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.2590 - val_accuracy: 0.9415 - val_loss: 0.1790\n",
      "Epoch 12/100\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9010 - loss: 0.2507 - val_accuracy: 0.9298 - val_loss: 0.2197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16e37ccc8d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' ANN Model '''\n",
    "# Initializing ANN through tensorflow\n",
    "adam_optimizier = tf.keras.optimizers.Adam(learning_rate=.001)\n",
    "ANN_model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(shape=(30,)),  # Input Layer - Each Feature to a Node\n",
    "    tf.keras.layers.Dense(120, activation='relu'),  # First Dense Layer\n",
    "    tf.keras.layers.Dense(30, activation='relu'),  # Second Dense Layer\n",
    "    tf.keras.layers.Dense(15, activation='relu'),  # Third Dense Layer\n",
    "    tf.keras.layers.Dense(2, activation='softmax'),  # Last Dense Layer, classify as yes or no\n",
    "])\n",
    "\n",
    "ANN_model1.compile(optimizer=adam_optimizier, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "ANN_model1.fit(x=x_train, y=y_train, validation_data=[x_test, y_test], epochs=100, batch_size=32, verbose=1, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Model: {'C': 0.9, 'penalty': 'l1', 'solver': 'liblinear'}  with score 0.9521835443037976\n",
      "Logistic Regression Score: 0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "''' Optimizing Logicstic Regression Model '''\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore Warnings for grid search since some configurations are not compatible\n",
    "\n",
    "# Running Grid Search CV on Logistic Regression to find best parameters\n",
    "log_r_model = LogisticRegression(max_iter=250, random_state=42)\n",
    "params = {\n",
    "    'C':[i for i in np.arange(.8, 1.3, .1)],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga', 'newton-cg']\n",
    "}\n",
    "grid_search_logr = GridSearchCV(log_r_model, params, cv=5, n_jobs=-1, error_score=np.nan)  # Supress Warnings\n",
    "grid_search_logr.fit(x_train, y_train)\n",
    "\n",
    "# Getting best estimator and finding score\n",
    "print(f\"Best Logistic Regression Model: {grid_search_logr.best_params_}  with score {grid_search_logr.best_score_}\")\n",
    "log_r_model_optimal = grid_search_logr.best_estimator_\n",
    "print(f\"Logistic Regression Score: {log_r_model_optimal.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Logistic Regression Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        63\n",
      "           1       0.96      0.98      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Making Classification Report + Confusion Matrix for Best Estimator (Logistic Regression) '''\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Getting Prediction from Logistic Regression Model\n",
    "y_pred_1 = log_r_model_optimal.predict(x_test)\n",
    "\n",
    "# Outputting Classification Report\n",
    "print(f\"Classification Report for Logistic Regression Model:\\n{classification_report(y_test, y_pred_1)}\")\n",
    "\n",
    "# Displaying Confusion Matrix\n",
    "cm_1 = confusion_matrix(y_test, y_pred_1)\n",
    "dispcm_1 = ConfusionMatrixDisplay(cm_1)\n",
    "dispcm_1.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: RandomForestClassifier(max_depth=10, min_samples_split=8, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best Score: 0.9572784810126581\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Output:\\nBest Parameters: max_depth=10, min_samples_leaf=2, min_samples_split=6, n_jobs=-1, random_state=42\\nBest Score: 0.9631268436578171\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Using Random Forest '''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Creating Classifier\n",
    "rand_forest_model_1 = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "# Finding optimal parameters using GridSearchCV\n",
    "params = {\n",
    "    'n_estimators': [i for i in range(100, 600, 100)],  # Tuned as needed\n",
    "    'max_depth': [i for i in range(10, 100, 10)],\n",
    "    'min_samples_split': [i for i in range(2, 11, 1)],\n",
    "    'min_samples_leaf': [i for i in range(1, 6, 1)]\n",
    "}\n",
    "grid_search_rf = GridSearchCV(rand_forest_model_1, params, cv=5, n_jobs=-1)\n",
    "grid_search_rf.fit(x_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search_rf.best_estimator_}\")\n",
    "print(f\"Best Score: {grid_search_rf.best_score_}\")\n",
    "\n",
    "''' Output:\n",
    "Best Parameters: RandomForestClassifier(max_depth=10, min_samples_split=8, n_jobs=-1,\n",
    "                       random_state=42)\n",
    "Best Score: 0.9572784810126581\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: RandomForestClassifier(max_depth=9, min_samples_split=7, n_estimators=200,\n",
      "                       n_jobs=-1, random_state=42)\n",
      "Best Score: 0.9547468354430378\n",
      "Optimizing Random Forest Score: 0.9649122807017544\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        63\n",
      "           1       0.96      0.98      0.97       108\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.96      0.96       171\n",
      "weighted avg       0.96      0.96      0.96       171\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Further optimizing model & outputting metrics '''\n",
    "params_2 = {\n",
    "    'max_depth': [i for i in range(8, 15, 1)],\n",
    "    'n_estimators': [i for i in range(200, 600, 100)],  # Limited due to computational expendenture\n",
    "    'min_samples_split': [i for i in range(5, 8)]\n",
    "}\n",
    "grid_search_rf_2 = GridSearchCV(rand_forest_model_1, params_2, cv=5, n_jobs=-1)\n",
    "grid_search_rf_2.fit(x_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search_rf_2.best_estimator_}\")\n",
    "print(f\"Best Score: {grid_search_rf_2.best_score_}\")\n",
    "rand_forest_model_optimal_1 = grid_search_rf_2.best_estimator_\n",
    "print(f\"Optimizing Random Forest Score: {rand_forest_model_optimal_1.score(x_test, y_test)}\")\n",
    "y_pred_rf_1 = rand_forest_model_optimal_1.predict(x_test)\n",
    "print(f\"Classification Report:\\n{classification_report(y_test, y_pred_rf_1)}\")\n",
    "cm = confusion_matrix(y_test, y_pred_rf_1)\n",
    "cmDisp2 = ConfusionMatrixDisplay(cm)\n",
    "cmDisp2.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of Attached Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gathering & Standardizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48632392 -1.72816419 -0.77640482 -0.45309111 -0.35412975  0.70673541\n",
      " -0.40893094  2.67917685  0.3929992  -0.24783755 -0.16053869 -0.77736335\n",
      " -0.71727488 -0.53322342 -0.82927637 -0.62487059 -0.6828818  -0.35615409\n",
      " -0.66454867 -0.55384128 -0.48149559 -0.64713678 -1.07596197 -0.40003878\n",
      " -0.51907075 -0.89653917 -0.62866023 -0.59188275 -0.98235003 -0.89097806\n",
      " -0.72391784 -0.72802959 -0.71613004 -0.55265327 -0.48436601 -0.97367098\n",
      " -1.01537682 -0.7237145   1.19573131  0.32055711  1.40193256  0.20214644\n",
      " -0.49480525  0.26937334  0.490303    0.38128607  0.17114468 -0.02921831\n",
      " -0.06706976 -0.08878676 -0.22696959 -0.52118647  1.83335549  0.36296114\n",
      "  0.89839577  0.32980398 -0.29314867 -0.04231752  0.57338166  1.40470933\n",
      "  1.41983513  1.25572074  0.5054956   0.16766576 -0.01308024]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Extract Features and Targets\n",
    "attached_df = pd.read_csv(\"Project3_Dataset.csv\")\n",
    "X = attached_df.iloc[:, :-1]  # Extract columns 1-65 (features)\n",
    "y = attached_df.iloc[:, -1]  # Extract column 66 (target)\n",
    "\n",
    "# Normalizing features using standard scaler\n",
    "scaler = StandardScaler()\n",
    "normalized_X = scaler.fit_transform(X)\n",
    "\n",
    "# Printing some of new X to ensure transformation\n",
    "print(normalized_X[5])\n",
    "\n",
    "# Splitting into training & testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(normalized_X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Best Baseline Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score:  0.65\n"
     ]
    }
   ],
   "source": [
    "''' Utilizing Naive Bayes Classifier as Baseline Accuracy '''\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "nbc_model2 = GaussianNB()\n",
    "nbc_model2.fit(x_train, y_train)\n",
    "nbc_model2_y_pred = nbc_model2.predict(x_test)\n",
    "print(\"Naive Bayes Accuracy Score: \", accuracy_score(y_test, nbc_model2_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Model: {'C': 0.7000000000000001, 'penalty': 'l2', 'solver': 'saga'}  with score 0.6407258064516128\n",
      "Logistic Regression Score: 0.7\n"
     ]
    }
   ],
   "source": [
    "''' Logistic Regression Model '''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # Ignore Warnings for grid search since some configurations are not compatible\n",
    "\n",
    "# Running Grid Search CV on Logistic Regression to find best parameters\n",
    "log_r_model2 = LogisticRegression(max_iter=250, random_state=42)\n",
    "params = {\n",
    "    'C':[i for i in np.arange(.1, .8, .1)],  # Tweaked after testing\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'solver': ['liblinear', 'lbfgs', 'saga', 'newton-cg']\n",
    "}\n",
    "grid_search_logr2 = GridSearchCV(log_r_model2, params, cv=5, n_jobs=-1, error_score=np.nan)  # Supress Warnings\n",
    "grid_search_logr2.fit(x_train, y_train)\n",
    "\n",
    "# Getting best estimator and finding score\n",
    "print(f\"Best Logistic Regression Model: {grid_search_logr2.best_params_}  with score {grid_search_logr2.best_score_}\")\n",
    "log_r_model_optimal2 = grid_search_logr2.best_estimator_\n",
    "print(f\"Logistic Regression Score: {log_r_model_optimal2.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC Model: {'C': 180, 'class_weight': None, 'degree': 2, 'gamma': 0.001, 'kernel': 'rbf'} with score 0.6471774193548386\n",
      "SVM Score: 0.6\n"
     ]
    }
   ],
   "source": [
    "''' Attempting SVM to acheive higher accuracy than Logistic Regression '''\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Creating Grid Search to later be tweaked\n",
    "params_3 = {\n",
    "    'C': [i for i in range(100, 200, 10)],  # Tweaked\n",
    "    'kernel': ['linear', 'rbf', 'poly'],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01],\n",
    "    'degree': [2, 3],\n",
    "    'class_weight': [None, 'balanced'],\n",
    "}\n",
    "svc_model = SVC()\n",
    "grid_search_svc = GridSearchCV(svc_model, params_3, cv=5, n_jobs=-1)\n",
    "grid_search_svc.fit(x_train, y_train)\n",
    "\n",
    "# Getting best estimator\n",
    "print(f\"Best SVC Model: {grid_search_svc.best_params_} with score {grid_search_svc.best_score_}\")\n",
    "svc_model_optimal = grid_search_svc.best_estimator_\n",
    "print(f\"SVM Score: {svc_model_optimal.score(x_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.0639 - loss: 8.2539 - val_accuracy: 0.0500 - val_loss: 7.4577 - learning_rate: 0.0010\n",
      "Epoch 2/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0812 - loss: 7.9310 - val_accuracy: 0.0750 - val_loss: 7.3274 - learning_rate: 0.0010\n",
      "Epoch 3/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0790 - loss: 7.8263 - val_accuracy: 0.1250 - val_loss: 7.2080 - learning_rate: 0.0010\n",
      "Epoch 4/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0648 - loss: 7.3820 - val_accuracy: 0.1500 - val_loss: 7.0949 - learning_rate: 0.0010\n",
      "Epoch 5/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0496 - loss: 7.3411 - val_accuracy: 0.1500 - val_loss: 6.9850 - learning_rate: 0.0010\n",
      "Epoch 6/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1533 - loss: 7.0662 - val_accuracy: 0.1500 - val_loss: 6.8770 - learning_rate: 0.0010\n",
      "Epoch 7/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1125 - loss: 7.0846 - val_accuracy: 0.1000 - val_loss: 6.7699 - learning_rate: 0.0010\n",
      "Epoch 8/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1795 - loss: 6.7953 - val_accuracy: 0.1250 - val_loss: 6.6668 - learning_rate: 0.0010\n",
      "Epoch 9/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1960 - loss: 6.6051 - val_accuracy: 0.1250 - val_loss: 6.5722 - learning_rate: 0.0010\n",
      "Epoch 10/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1692 - loss: 6.6010 - val_accuracy: 0.1000 - val_loss: 6.4789 - learning_rate: 0.0010\n",
      "Epoch 11/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1648 - loss: 6.3914 - val_accuracy: 0.1250 - val_loss: 6.3875 - learning_rate: 0.0010\n",
      "Epoch 12/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1669 - loss: 6.4208 - val_accuracy: 0.0750 - val_loss: 6.2996 - learning_rate: 0.0010\n",
      "Epoch 13/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2556 - loss: 6.1019 - val_accuracy: 0.1000 - val_loss: 6.2113 - learning_rate: 0.0010\n",
      "Epoch 14/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2155 - loss: 5.9362 - val_accuracy: 0.1250 - val_loss: 6.1218 - learning_rate: 0.0010\n",
      "Epoch 15/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2012 - loss: 5.9198 - val_accuracy: 0.1250 - val_loss: 6.0355 - learning_rate: 0.0010\n",
      "Epoch 16/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2434 - loss: 5.7820 - val_accuracy: 0.1250 - val_loss: 5.9482 - learning_rate: 0.0010\n",
      "Epoch 17/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2501 - loss: 5.6892 - val_accuracy: 0.1500 - val_loss: 5.8573 - learning_rate: 0.0010\n",
      "Epoch 18/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2642 - loss: 5.7026 - val_accuracy: 0.2250 - val_loss: 5.7687 - learning_rate: 0.0010\n",
      "Epoch 19/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2355 - loss: 5.5249 - val_accuracy: 0.2250 - val_loss: 5.6832 - learning_rate: 0.0010\n",
      "Epoch 20/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2979 - loss: 5.4545 - val_accuracy: 0.2500 - val_loss: 5.5975 - learning_rate: 0.0010\n",
      "Epoch 21/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2888 - loss: 5.3552 - val_accuracy: 0.2250 - val_loss: 5.5128 - learning_rate: 0.0010\n",
      "Epoch 22/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3944 - loss: 5.0734 - val_accuracy: 0.2750 - val_loss: 5.4327 - learning_rate: 0.0010\n",
      "Epoch 23/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3216 - loss: 5.2195 - val_accuracy: 0.3250 - val_loss: 5.3549 - learning_rate: 0.0010\n",
      "Epoch 24/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3748 - loss: 4.9261 - val_accuracy: 0.2750 - val_loss: 5.2800 - learning_rate: 0.0010\n",
      "Epoch 25/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.3682 - loss: 4.8281 - val_accuracy: 0.2750 - val_loss: 5.2099 - learning_rate: 0.0010\n",
      "Epoch 26/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3602 - loss: 4.8410 - val_accuracy: 0.3000 - val_loss: 5.1442 - learning_rate: 0.0010\n",
      "Epoch 27/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4315 - loss: 4.6032 - val_accuracy: 0.3250 - val_loss: 5.0769 - learning_rate: 0.0010\n",
      "Epoch 28/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4218 - loss: 4.5653 - val_accuracy: 0.3500 - val_loss: 5.0063 - learning_rate: 0.0010\n",
      "Epoch 29/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4444 - loss: 4.4316 - val_accuracy: 0.3500 - val_loss: 4.9436 - learning_rate: 0.0010\n",
      "Epoch 30/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3716 - loss: 4.5868 - val_accuracy: 0.3000 - val_loss: 4.8769 - learning_rate: 0.0010\n",
      "Epoch 31/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4040 - loss: 4.5048 - val_accuracy: 0.3250 - val_loss: 4.8042 - learning_rate: 0.0010\n",
      "Epoch 32/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4198 - loss: 4.3024 - val_accuracy: 0.3250 - val_loss: 4.7264 - learning_rate: 0.0010\n",
      "Epoch 33/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4581 - loss: 4.1487 - val_accuracy: 0.3750 - val_loss: 4.6569 - learning_rate: 0.0010\n",
      "Epoch 34/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4603 - loss: 4.2611 - val_accuracy: 0.3750 - val_loss: 4.5971 - learning_rate: 0.0010\n",
      "Epoch 35/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4246 - loss: 4.1745 - val_accuracy: 0.3750 - val_loss: 4.5390 - learning_rate: 0.0010\n",
      "Epoch 36/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4460 - loss: 4.1137 - val_accuracy: 0.4000 - val_loss: 4.4841 - learning_rate: 0.0010\n",
      "Epoch 37/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4214 - loss: 3.9992 - val_accuracy: 0.4250 - val_loss: 4.4268 - learning_rate: 0.0010\n",
      "Epoch 38/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4546 - loss: 3.8481 - val_accuracy: 0.4000 - val_loss: 4.3785 - learning_rate: 0.0010\n",
      "Epoch 39/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5068 - loss: 3.8186 - val_accuracy: 0.4000 - val_loss: 4.3151 - learning_rate: 0.0010\n",
      "Epoch 40/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5242 - loss: 3.7519 - val_accuracy: 0.4250 - val_loss: 4.2439 - learning_rate: 0.0010\n",
      "Epoch 41/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5576 - loss: 3.6228 - val_accuracy: 0.4250 - val_loss: 4.1788 - learning_rate: 0.0010\n",
      "Epoch 42/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5186 - loss: 3.6214 - val_accuracy: 0.4000 - val_loss: 4.1235 - learning_rate: 0.0010\n",
      "Epoch 43/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5144 - loss: 3.6717 - val_accuracy: 0.4000 - val_loss: 4.0672 - learning_rate: 0.0010\n",
      "Epoch 44/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5656 - loss: 3.4964 - val_accuracy: 0.4000 - val_loss: 4.0246 - learning_rate: 0.0010\n",
      "Epoch 45/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5034 - loss: 3.4945 - val_accuracy: 0.3750 - val_loss: 3.9868 - learning_rate: 0.0010\n",
      "Epoch 46/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5458 - loss: 3.3604 - val_accuracy: 0.3750 - val_loss: 3.9348 - learning_rate: 0.0010\n",
      "Epoch 47/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4893 - loss: 3.4831 - val_accuracy: 0.4250 - val_loss: 3.8830 - learning_rate: 0.0010\n",
      "Epoch 48/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5753 - loss: 3.2954 - val_accuracy: 0.4250 - val_loss: 3.8273 - learning_rate: 0.0010\n",
      "Epoch 49/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5756 - loss: 3.1346 - val_accuracy: 0.4750 - val_loss: 3.7727 - learning_rate: 0.0010\n",
      "Epoch 50/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6089 - loss: 3.1980 - val_accuracy: 0.5000 - val_loss: 3.7269 - learning_rate: 0.0010\n",
      "Epoch 51/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4935 - loss: 3.1950 - val_accuracy: 0.5000 - val_loss: 3.6941 - learning_rate: 0.0010\n",
      "Epoch 52/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6683 - loss: 2.9308 - val_accuracy: 0.4750 - val_loss: 3.6592 - learning_rate: 0.0010\n",
      "Epoch 53/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5968 - loss: 3.0027 - val_accuracy: 0.4750 - val_loss: 3.6152 - learning_rate: 0.0010\n",
      "Epoch 54/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5873 - loss: 3.0366 - val_accuracy: 0.4750 - val_loss: 3.5569 - learning_rate: 0.0010\n",
      "Epoch 55/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5994 - loss: 2.9186 - val_accuracy: 0.4750 - val_loss: 3.5164 - learning_rate: 0.0010\n",
      "Epoch 56/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5820 - loss: 2.9786 - val_accuracy: 0.4500 - val_loss: 3.4656 - learning_rate: 0.0010\n",
      "Epoch 57/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5546 - loss: 2.9050 - val_accuracy: 0.4750 - val_loss: 3.4057 - learning_rate: 0.0010\n",
      "Epoch 58/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5682 - loss: 2.9433 - val_accuracy: 0.4750 - val_loss: 3.3468 - learning_rate: 0.0010\n",
      "Epoch 59/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6435 - loss: 2.7974 - val_accuracy: 0.5250 - val_loss: 3.3231 - learning_rate: 0.0010\n",
      "Epoch 60/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6732 - loss: 2.6474 - val_accuracy: 0.4750 - val_loss: 3.3052 - learning_rate: 0.0010\n",
      "Epoch 61/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6425 - loss: 2.6731 - val_accuracy: 0.5000 - val_loss: 3.2695 - learning_rate: 0.0010\n",
      "Epoch 62/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5715 - loss: 2.6523 - val_accuracy: 0.4500 - val_loss: 3.2190 - learning_rate: 0.0010\n",
      "Epoch 63/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7304 - loss: 2.5855 - val_accuracy: 0.5250 - val_loss: 3.1554 - learning_rate: 0.0010\n",
      "Epoch 64/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6433 - loss: 2.5575 - val_accuracy: 0.5500 - val_loss: 3.1098 - learning_rate: 0.0010\n",
      "Epoch 65/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6640 - loss: 2.5665 - val_accuracy: 0.5250 - val_loss: 3.0859 - learning_rate: 0.0010\n",
      "Epoch 66/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6538 - loss: 2.4594 - val_accuracy: 0.5000 - val_loss: 3.0736 - learning_rate: 0.0010\n",
      "Epoch 67/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6530 - loss: 2.4856 - val_accuracy: 0.5500 - val_loss: 3.0360 - learning_rate: 0.0010\n",
      "Epoch 68/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6396 - loss: 2.5323 - val_accuracy: 0.5500 - val_loss: 2.9974 - learning_rate: 0.0010\n",
      "Epoch 69/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6829 - loss: 2.3125 - val_accuracy: 0.4750 - val_loss: 2.9664 - learning_rate: 0.0010\n",
      "Epoch 70/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6420 - loss: 2.3285 - val_accuracy: 0.5000 - val_loss: 2.9117 - learning_rate: 0.0010\n",
      "Epoch 71/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6658 - loss: 2.3371 - val_accuracy: 0.5250 - val_loss: 2.8581 - learning_rate: 0.0010\n",
      "Epoch 72/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6051 - loss: 2.3905 - val_accuracy: 0.5250 - val_loss: 2.8075 - learning_rate: 0.0010\n",
      "Epoch 73/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7005 - loss: 2.2040 - val_accuracy: 0.5500 - val_loss: 2.7564 - learning_rate: 0.0010\n",
      "Epoch 74/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6935 - loss: 2.2020 - val_accuracy: 0.6000 - val_loss: 2.7230 - learning_rate: 0.0010\n",
      "Epoch 75/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6477 - loss: 2.1679 - val_accuracy: 0.6250 - val_loss: 2.6893 - learning_rate: 0.0010\n",
      "Epoch 76/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6488 - loss: 2.1155 - val_accuracy: 0.6250 - val_loss: 2.6775 - learning_rate: 0.0010\n",
      "Epoch 77/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5828 - loss: 2.2853 - val_accuracy: 0.6250 - val_loss: 2.6515 - learning_rate: 0.0010\n",
      "Epoch 78/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6879 - loss: 2.1107 - val_accuracy: 0.6000 - val_loss: 2.6184 - learning_rate: 0.0010\n",
      "Epoch 79/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7248 - loss: 2.0299 - val_accuracy: 0.6000 - val_loss: 2.5858 - learning_rate: 0.0010\n",
      "Epoch 80/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7510 - loss: 2.0074 - val_accuracy: 0.6500 - val_loss: 2.5637 - learning_rate: 0.0010\n",
      "Epoch 81/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7180 - loss: 2.0917 - val_accuracy: 0.6500 - val_loss: 2.5436 - learning_rate: 0.0010\n",
      "Epoch 82/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6056 - loss: 2.1154 - val_accuracy: 0.6500 - val_loss: 2.5195 - learning_rate: 0.0010\n",
      "Epoch 83/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6957 - loss: 1.9428 - val_accuracy: 0.6000 - val_loss: 2.5024 - learning_rate: 0.0010\n",
      "Epoch 84/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7440 - loss: 1.9489 - val_accuracy: 0.6000 - val_loss: 2.4874 - learning_rate: 0.0010\n",
      "Epoch 85/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7175 - loss: 1.9519 - val_accuracy: 0.6250 - val_loss: 2.4518 - learning_rate: 0.0010\n",
      "Epoch 86/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6752 - loss: 2.0478 - val_accuracy: 0.6500 - val_loss: 2.3962 - learning_rate: 0.0010\n",
      "Epoch 87/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7231 - loss: 1.8245 - val_accuracy: 0.6250 - val_loss: 2.3584 - learning_rate: 0.0010\n",
      "Epoch 88/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7198 - loss: 1.9073 - val_accuracy: 0.6500 - val_loss: 2.3299 - learning_rate: 0.0010\n",
      "Epoch 89/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7681 - loss: 1.7742 - val_accuracy: 0.6750 - val_loss: 2.3161 - learning_rate: 0.0010\n",
      "Epoch 90/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7246 - loss: 1.7971 - val_accuracy: 0.7000 - val_loss: 2.3001 - learning_rate: 0.0010\n",
      "Epoch 91/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7847 - loss: 1.6096 - val_accuracy: 0.6500 - val_loss: 2.2724 - learning_rate: 0.0010\n",
      "Epoch 92/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7608 - loss: 1.7357 - val_accuracy: 0.6750 - val_loss: 2.2600 - learning_rate: 0.0010\n",
      "Epoch 93/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7735 - loss: 1.6670 - val_accuracy: 0.6500 - val_loss: 2.2609 - learning_rate: 0.0010\n",
      "Epoch 94/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7277 - loss: 1.6969 - val_accuracy: 0.6000 - val_loss: 2.2576 - learning_rate: 0.0010\n",
      "Epoch 95/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7469 - loss: 1.7374 - val_accuracy: 0.6500 - val_loss: 2.1936 - learning_rate: 0.0010\n",
      "Epoch 96/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7518 - loss: 1.6768 - val_accuracy: 0.6250 - val_loss: 2.1570 - learning_rate: 0.0010\n",
      "Epoch 97/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7648 - loss: 1.5811 - val_accuracy: 0.6000 - val_loss: 2.1145 - learning_rate: 0.0010\n",
      "Epoch 98/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6239 - loss: 1.7807 - val_accuracy: 0.6250 - val_loss: 2.0723 - learning_rate: 0.0010\n",
      "Epoch 99/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7467 - loss: 1.7068 - val_accuracy: 0.6000 - val_loss: 2.0840 - learning_rate: 0.0010\n",
      "Epoch 100/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7931 - loss: 1.5238 - val_accuracy: 0.5750 - val_loss: 2.1182 - learning_rate: 0.0010\n",
      "Epoch 101/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7630 - loss: 1.5099 - val_accuracy: 0.5750 - val_loss: 2.0833 - learning_rate: 0.0010\n",
      "Epoch 102/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8534 - loss: 1.4552 - val_accuracy: 0.6000 - val_loss: 2.0190 - learning_rate: 0.0010\n",
      "Epoch 103/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8244 - loss: 1.4575 - val_accuracy: 0.6500 - val_loss: 1.9676 - learning_rate: 0.0010\n",
      "Epoch 104/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7448 - loss: 1.5404 - val_accuracy: 0.6750 - val_loss: 1.9402 - learning_rate: 0.0010\n",
      "Epoch 105/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7543 - loss: 1.4992 - val_accuracy: 0.6250 - val_loss: 1.9457 - learning_rate: 0.0010\n",
      "Epoch 106/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6938 - loss: 1.5757 - val_accuracy: 0.6250 - val_loss: 1.9173 - learning_rate: 0.0010\n",
      "Epoch 107/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7751 - loss: 1.4694 - val_accuracy: 0.6500 - val_loss: 1.8861 - learning_rate: 0.0010\n",
      "Epoch 108/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7378 - loss: 1.4832 - val_accuracy: 0.6750 - val_loss: 1.8827 - learning_rate: 0.0010\n",
      "Epoch 109/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7833 - loss: 1.4326 - val_accuracy: 0.6250 - val_loss: 1.8792 - learning_rate: 0.0010\n",
      "Epoch 110/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7188 - loss: 1.4750 - val_accuracy: 0.6250 - val_loss: 1.8548 - learning_rate: 0.0010\n",
      "Epoch 111/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7767 - loss: 1.4407 - val_accuracy: 0.6750 - val_loss: 1.8104 - learning_rate: 0.0010\n",
      "Epoch 112/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7703 - loss: 1.4101 - val_accuracy: 0.6750 - val_loss: 1.8018 - learning_rate: 0.0010\n",
      "Epoch 113/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7274 - loss: 1.4379 - val_accuracy: 0.7000 - val_loss: 1.7831 - learning_rate: 0.0010\n",
      "Epoch 114/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7701 - loss: 1.3981 - val_accuracy: 0.6500 - val_loss: 1.7534 - learning_rate: 0.0010\n",
      "Epoch 115/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8453 - loss: 1.2769 - val_accuracy: 0.6750 - val_loss: 1.7358 - learning_rate: 0.0010\n",
      "Epoch 116/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7694 - loss: 1.3591 - val_accuracy: 0.6500 - val_loss: 1.7379 - learning_rate: 0.0010\n",
      "Epoch 117/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7738 - loss: 1.3571 - val_accuracy: 0.6750 - val_loss: 1.7360 - learning_rate: 0.0010\n",
      "Epoch 118/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8036 - loss: 1.2886 - val_accuracy: 0.7250 - val_loss: 1.7076 - learning_rate: 0.0010\n",
      "Epoch 119/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8585 - loss: 1.1715 - val_accuracy: 0.6750 - val_loss: 1.6866 - learning_rate: 0.0010\n",
      "Epoch 120/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8266 - loss: 1.1834 - val_accuracy: 0.7000 - val_loss: 1.6688 - learning_rate: 0.0010\n",
      "Epoch 121/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8532 - loss: 1.2278 - val_accuracy: 0.7000 - val_loss: 1.6508 - learning_rate: 0.0010\n",
      "Epoch 122/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8179 - loss: 1.2201 - val_accuracy: 0.6750 - val_loss: 1.6468 - learning_rate: 0.0010\n",
      "Epoch 123/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8277 - loss: 1.2423 - val_accuracy: 0.6750 - val_loss: 1.6679 - learning_rate: 0.0010\n",
      "Epoch 124/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8022 - loss: 1.2271 - val_accuracy: 0.6500 - val_loss: 1.6448 - learning_rate: 0.0010\n",
      "Epoch 125/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7611 - loss: 1.3041 - val_accuracy: 0.7000 - val_loss: 1.5864 - learning_rate: 0.0010\n",
      "Epoch 126/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7828 - loss: 1.1798 - val_accuracy: 0.7000 - val_loss: 1.5372 - learning_rate: 0.0010\n",
      "Epoch 127/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8464 - loss: 1.1216 - val_accuracy: 0.7000 - val_loss: 1.5254 - learning_rate: 0.0010\n",
      "Epoch 128/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7949 - loss: 1.1712 - val_accuracy: 0.7000 - val_loss: 1.5152 - learning_rate: 0.0010\n",
      "Epoch 129/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7715 - loss: 1.2112 - val_accuracy: 0.7000 - val_loss: 1.5248 - learning_rate: 0.0010\n",
      "Epoch 130/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8421 - loss: 1.1020 - val_accuracy: 0.6750 - val_loss: 1.5134 - learning_rate: 0.0010\n",
      "Epoch 131/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8235 - loss: 1.1067 - val_accuracy: 0.6750 - val_loss: 1.4818 - learning_rate: 0.0010\n",
      "Epoch 132/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8221 - loss: 1.0897 - val_accuracy: 0.6750 - val_loss: 1.4534 - learning_rate: 0.0010\n",
      "Epoch 133/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8259 - loss: 1.0878 - val_accuracy: 0.6750 - val_loss: 1.4476 - learning_rate: 0.0010\n",
      "Epoch 134/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8234 - loss: 1.0484 - val_accuracy: 0.7250 - val_loss: 1.4428 - learning_rate: 0.0010\n",
      "Epoch 135/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8749 - loss: 0.9968 - val_accuracy: 0.7000 - val_loss: 1.4408 - learning_rate: 0.0010\n",
      "Epoch 136/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8611 - loss: 1.0397 - val_accuracy: 0.7000 - val_loss: 1.4366 - learning_rate: 0.0010\n",
      "Epoch 137/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8450 - loss: 1.0546 - val_accuracy: 0.7000 - val_loss: 1.4304 - learning_rate: 0.0010\n",
      "Epoch 138/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8783 - loss: 0.9305 - val_accuracy: 0.7000 - val_loss: 1.4346 - learning_rate: 0.0010\n",
      "Epoch 139/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9155 - loss: 0.9732 - val_accuracy: 0.7000 - val_loss: 1.4219 - learning_rate: 0.0010\n",
      "Epoch 140/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9055 - loss: 0.9331 - val_accuracy: 0.7000 - val_loss: 1.4162 - learning_rate: 0.0010\n",
      "Epoch 141/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8670 - loss: 0.9849 - val_accuracy: 0.6500 - val_loss: 1.4249 - learning_rate: 0.0010\n",
      "Epoch 142/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8908 - loss: 0.9767 - val_accuracy: 0.6500 - val_loss: 1.4461 - learning_rate: 0.0010\n",
      "Epoch 143/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8100 - loss: 1.0056 - val_accuracy: 0.6500 - val_loss: 1.4640 - learning_rate: 0.0010\n",
      "Epoch 144/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8220 - loss: 1.0784 - val_accuracy: 0.6500 - val_loss: 1.4476 - learning_rate: 0.0010\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8750 - loss: 0.9422\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8587 - loss: 0.9384 - val_accuracy: 0.6500 - val_loss: 1.4233 - learning_rate: 0.0010\n",
      "Epoch 146/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8347 - loss: 1.0114 - val_accuracy: 0.6750 - val_loss: 1.3887 - learning_rate: 5.0000e-04\n",
      "Epoch 147/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8783 - loss: 0.9852 - val_accuracy: 0.6500 - val_loss: 1.3400 - learning_rate: 5.0000e-04\n",
      "Epoch 148/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8220 - loss: 0.9453 - val_accuracy: 0.6750 - val_loss: 1.3081 - learning_rate: 5.0000e-04\n",
      "Epoch 149/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8947 - loss: 0.8495 - val_accuracy: 0.6750 - val_loss: 1.2844 - learning_rate: 5.0000e-04\n",
      "Epoch 150/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8528 - loss: 0.9621 - val_accuracy: 0.6750 - val_loss: 1.2815 - learning_rate: 5.0000e-04\n",
      "Epoch 151/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8813 - loss: 0.9373 - val_accuracy: 0.6750 - val_loss: 1.2905 - learning_rate: 5.0000e-04\n",
      "Epoch 152/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8943 - loss: 0.8252 - val_accuracy: 0.6750 - val_loss: 1.3076 - learning_rate: 5.0000e-04\n",
      "Epoch 153/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9106 - loss: 0.8041 - val_accuracy: 0.6750 - val_loss: 1.3169 - learning_rate: 5.0000e-04\n",
      "Epoch 154/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8632 - loss: 0.9026 - val_accuracy: 0.6500 - val_loss: 1.3175 - learning_rate: 5.0000e-04\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9062 - loss: 0.7942\n",
      "Epoch 155: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8430 - loss: 0.9369 - val_accuracy: 0.6500 - val_loss: 1.2880 - learning_rate: 5.0000e-04\n",
      "Epoch 156/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8493 - loss: 0.9416 - val_accuracy: 0.6500 - val_loss: 1.2676 - learning_rate: 2.5000e-04\n",
      "Epoch 157/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8684 - loss: 0.8594 - val_accuracy: 0.6500 - val_loss: 1.2518 - learning_rate: 2.5000e-04\n",
      "Epoch 158/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8129 - loss: 1.0025 - val_accuracy: 0.6750 - val_loss: 1.2447 - learning_rate: 2.5000e-04\n",
      "Epoch 159/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8644 - loss: 0.8900 - val_accuracy: 0.6750 - val_loss: 1.2501 - learning_rate: 2.5000e-04\n",
      "Epoch 160/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9110 - loss: 0.8357 - val_accuracy: 0.7500 - val_loss: 1.2709 - learning_rate: 2.5000e-04\n",
      "Epoch 161/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8733 - loss: 0.8499 - val_accuracy: 0.7500 - val_loss: 1.2757 - learning_rate: 2.5000e-04\n",
      "Epoch 162/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9007 - loss: 0.8342 - val_accuracy: 0.6750 - val_loss: 1.2731 - learning_rate: 2.5000e-04\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8125 - loss: 0.8826\n",
      "Epoch 163: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8734 - loss: 0.8354 - val_accuracy: 0.6750 - val_loss: 1.2625 - learning_rate: 2.5000e-04\n",
      "Epoch 164/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8700 - loss: 0.8576 - val_accuracy: 0.7000 - val_loss: 1.2499 - learning_rate: 1.2500e-04\n",
      "Epoch 165/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9076 - loss: 0.8677 - val_accuracy: 0.7000 - val_loss: 1.2389 - learning_rate: 1.2500e-04\n",
      "Epoch 166/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9055 - loss: 0.8344 - val_accuracy: 0.6750 - val_loss: 1.2275 - learning_rate: 1.2500e-04\n",
      "Epoch 167/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8751 - loss: 0.8531 - val_accuracy: 0.6750 - val_loss: 1.2205 - learning_rate: 1.2500e-04\n",
      "Epoch 168/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9047 - loss: 0.8439 - val_accuracy: 0.6750 - val_loss: 1.2159 - learning_rate: 1.2500e-04\n",
      "Epoch 169/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9184 - loss: 0.7714 - val_accuracy: 0.6750 - val_loss: 1.2098 - learning_rate: 1.2500e-04\n",
      "Epoch 170/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9137 - loss: 0.7705 - val_accuracy: 0.6750 - val_loss: 1.2079 - learning_rate: 1.2500e-04\n",
      "Epoch 171/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9270 - loss: 0.7364 - val_accuracy: 0.6750 - val_loss: 1.2082 - learning_rate: 1.2500e-04\n",
      "Epoch 172/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9590 - loss: 0.7145 - val_accuracy: 0.6750 - val_loss: 1.2075 - learning_rate: 1.2500e-04\n",
      "Epoch 173/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9492 - loss: 0.7390 - val_accuracy: 0.6750 - val_loss: 1.2052 - learning_rate: 1.2500e-04\n",
      "Epoch 174/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8921 - loss: 0.8725 - val_accuracy: 0.6750 - val_loss: 1.2009 - learning_rate: 1.2500e-04\n",
      "Epoch 175/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9172 - loss: 0.7731 - val_accuracy: 0.6750 - val_loss: 1.2003 - learning_rate: 1.2500e-04\n",
      "Epoch 176/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9359 - loss: 0.7420 - val_accuracy: 0.6750 - val_loss: 1.1995 - learning_rate: 1.2500e-04\n",
      "Epoch 177/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9134 - loss: 0.7766 - val_accuracy: 0.6750 - val_loss: 1.1984 - learning_rate: 1.2500e-04\n",
      "Epoch 178/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8674 - loss: 0.9429 - val_accuracy: 0.6750 - val_loss: 1.1883 - learning_rate: 1.2500e-04\n",
      "Epoch 179/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8903 - loss: 0.8240 - val_accuracy: 0.6750 - val_loss: 1.1779 - learning_rate: 1.2500e-04\n",
      "Epoch 180/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8739 - loss: 0.7528 - val_accuracy: 0.6750 - val_loss: 1.1712 - learning_rate: 1.2500e-04\n",
      "Epoch 181/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8947 - loss: 0.7933 - val_accuracy: 0.6750 - val_loss: 1.1741 - learning_rate: 1.2500e-04\n",
      "Epoch 182/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8960 - loss: 0.7723 - val_accuracy: 0.6750 - val_loss: 1.1758 - learning_rate: 1.2500e-04\n",
      "Epoch 183/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8939 - loss: 0.7790 - val_accuracy: 0.6750 - val_loss: 1.1790 - learning_rate: 1.2500e-04\n",
      "Epoch 184/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9305 - loss: 0.7525 - val_accuracy: 0.7000 - val_loss: 1.1846 - learning_rate: 1.2500e-04\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9375 - loss: 0.7343\n",
      "Epoch 185: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9270 - loss: 0.7587 - val_accuracy: 0.7000 - val_loss: 1.1860 - learning_rate: 1.2500e-04\n",
      "Epoch 186/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9284 - loss: 0.7302 - val_accuracy: 0.7000 - val_loss: 1.1841 - learning_rate: 6.2500e-05\n",
      "Epoch 187/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9079 - loss: 0.8241 - val_accuracy: 0.7000 - val_loss: 1.1825 - learning_rate: 6.2500e-05\n",
      "Epoch 188/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9399 - loss: 0.7268 - val_accuracy: 0.7000 - val_loss: 1.1814 - learning_rate: 6.2500e-05\n",
      "Epoch 189/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8544 - loss: 0.8538 - val_accuracy: 0.6750 - val_loss: 1.1788 - learning_rate: 6.2500e-05\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8750 - loss: 0.7506\n",
      "Epoch 190: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8951 - loss: 0.7905 - val_accuracy: 0.6750 - val_loss: 1.1791 - learning_rate: 6.2500e-05\n",
      "Epoch 191/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9526 - loss: 0.7110 - val_accuracy: 0.6750 - val_loss: 1.1787 - learning_rate: 3.1250e-05\n",
      "Epoch 192/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9076 - loss: 0.7913 - val_accuracy: 0.6750 - val_loss: 1.1770 - learning_rate: 3.1250e-05\n",
      "Epoch 193/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9081 - loss: 0.8238 - val_accuracy: 0.6750 - val_loss: 1.1763 - learning_rate: 3.1250e-05\n",
      "Epoch 194/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9207 - loss: 0.7285 - val_accuracy: 0.6750 - val_loss: 1.1757 - learning_rate: 3.1250e-05\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.6029\n",
      "Epoch 195: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9457 - loss: 0.7186 - val_accuracy: 0.6750 - val_loss: 1.1750 - learning_rate: 3.1250e-05\n",
      "Epoch 196/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9175 - loss: 0.7345 - val_accuracy: 0.6750 - val_loss: 1.1743 - learning_rate: 1.5625e-05\n",
      "Epoch 197/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8630 - loss: 0.8483 - val_accuracy: 0.6750 - val_loss: 1.1736 - learning_rate: 1.5625e-05\n",
      "Epoch 198/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8635 - loss: 0.8523 - val_accuracy: 0.6750 - val_loss: 1.1719 - learning_rate: 1.5625e-05\n",
      "Epoch 199/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9106 - loss: 0.7608 - val_accuracy: 0.6750 - val_loss: 1.1704 - learning_rate: 1.5625e-05\n",
      "Epoch 200/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8756 - loss: 0.8086 - val_accuracy: 0.6750 - val_loss: 1.1687 - learning_rate: 1.5625e-05\n",
      "Epoch 201/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9305 - loss: 0.7076 - val_accuracy: 0.6750 - val_loss: 1.1677 - learning_rate: 1.5625e-05\n",
      "Epoch 202/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8912 - loss: 0.8205 - val_accuracy: 0.6750 - val_loss: 1.1659 - learning_rate: 1.5625e-05\n",
      "Epoch 203/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9711 - loss: 0.6632 - val_accuracy: 0.6750 - val_loss: 1.1654 - learning_rate: 1.5625e-05\n",
      "Epoch 204/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9102 - loss: 0.8168 - val_accuracy: 0.6750 - val_loss: 1.1648 - learning_rate: 1.5625e-05\n",
      "Epoch 205/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8895 - loss: 0.7881 - val_accuracy: 0.6750 - val_loss: 1.1647 - learning_rate: 1.5625e-05\n",
      "Epoch 206/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8325 - loss: 0.8227 - val_accuracy: 0.6750 - val_loss: 1.1638 - learning_rate: 1.5625e-05\n",
      "Epoch 207/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9192 - loss: 0.7470 - val_accuracy: 0.6750 - val_loss: 1.1613 - learning_rate: 1.5625e-05\n",
      "Epoch 208/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9331 - loss: 0.7748 - val_accuracy: 0.6750 - val_loss: 1.1595 - learning_rate: 1.5625e-05\n",
      "Epoch 209/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9443 - loss: 0.6834 - val_accuracy: 0.6750 - val_loss: 1.1587 - learning_rate: 1.5625e-05\n",
      "Epoch 210/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8644 - loss: 0.8363 - val_accuracy: 0.6750 - val_loss: 1.1587 - learning_rate: 1.5625e-05\n",
      "Epoch 211/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9101 - loss: 0.7539 - val_accuracy: 0.6750 - val_loss: 1.1584 - learning_rate: 1.5625e-05\n",
      "Epoch 212/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8809 - loss: 0.8144 - val_accuracy: 0.6750 - val_loss: 1.1576 - learning_rate: 1.5625e-05\n",
      "Epoch 213/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9045 - loss: 0.7858 - val_accuracy: 0.6750 - val_loss: 1.1573 - learning_rate: 1.5625e-05\n",
      "Epoch 214/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8800 - loss: 0.8491 - val_accuracy: 0.6750 - val_loss: 1.1558 - learning_rate: 1.5625e-05\n",
      "Epoch 215/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9296 - loss: 0.7143 - val_accuracy: 0.6750 - val_loss: 1.1548 - learning_rate: 1.5625e-05\n",
      "Epoch 216/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9561 - loss: 0.6640 - val_accuracy: 0.6750 - val_loss: 1.1549 - learning_rate: 1.5625e-05\n",
      "Epoch 217/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9330 - loss: 0.7635 - val_accuracy: 0.6750 - val_loss: 1.1550 - learning_rate: 1.5625e-05\n",
      "Epoch 218/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8977 - loss: 0.7570 - val_accuracy: 0.6750 - val_loss: 1.1547 - learning_rate: 1.5625e-05\n",
      "Epoch 219/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9400 - loss: 0.6761 - val_accuracy: 0.6750 - val_loss: 1.1547 - learning_rate: 1.5625e-05\n",
      "Epoch 220/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9038 - loss: 0.7665 - val_accuracy: 0.6750 - val_loss: 1.1546 - learning_rate: 1.5625e-05\n",
      "Epoch 221/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8942 - loss: 0.7833 - val_accuracy: 0.6750 - val_loss: 1.1541 - learning_rate: 1.5625e-05\n",
      "Epoch 222/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8484 - loss: 0.8156 - val_accuracy: 0.6750 - val_loss: 1.1535 - learning_rate: 1.5625e-05\n",
      "Epoch 223/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9179 - loss: 0.7762 - val_accuracy: 0.6750 - val_loss: 1.1532 - learning_rate: 1.5625e-05\n",
      "Epoch 224/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9071 - loss: 0.7556 - val_accuracy: 0.6750 - val_loss: 1.1526 - learning_rate: 1.5625e-05\n",
      "Epoch 225/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8817 - loss: 0.8197 - val_accuracy: 0.6750 - val_loss: 1.1532 - learning_rate: 1.5625e-05\n",
      "Epoch 226/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9288 - loss: 0.7731 - val_accuracy: 0.6750 - val_loss: 1.1544 - learning_rate: 1.5625e-05\n",
      "Epoch 227/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8669 - loss: 0.8439 - val_accuracy: 0.6750 - val_loss: 1.1556 - learning_rate: 1.5625e-05\n",
      "Epoch 228/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8938 - loss: 0.7566 - val_accuracy: 0.6750 - val_loss: 1.1563 - learning_rate: 1.5625e-05\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9062 - loss: 0.7359\n",
      "Epoch 229: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9132 - loss: 0.7247 - val_accuracy: 0.6750 - val_loss: 1.1567 - learning_rate: 1.5625e-05\n",
      "Epoch 230/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9375 - loss: 0.7511 - val_accuracy: 0.6750 - val_loss: 1.1565 - learning_rate: 7.8125e-06\n",
      "Epoch 231/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8972 - loss: 0.7477 - val_accuracy: 0.6750 - val_loss: 1.1567 - learning_rate: 7.8125e-06\n",
      "Epoch 232/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9050 - loss: 0.7736 - val_accuracy: 0.6750 - val_loss: 1.1570 - learning_rate: 7.8125e-06\n",
      "Epoch 233/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9029 - loss: 0.7645 - val_accuracy: 0.6750 - val_loss: 1.1558 - learning_rate: 7.8125e-06\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9062 - loss: 0.6624\n",
      "Epoch 234: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9231 - loss: 0.6929 - val_accuracy: 0.6750 - val_loss: 1.1551 - learning_rate: 7.8125e-06\n",
      "Epoch 235/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9280 - loss: 0.7557 - val_accuracy: 0.6750 - val_loss: 1.1547 - learning_rate: 3.9063e-06\n",
      "Epoch 236/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9019 - loss: 0.7707 - val_accuracy: 0.6750 - val_loss: 1.1552 - learning_rate: 3.9063e-06\n",
      "Epoch 237/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9509 - loss: 0.7074 - val_accuracy: 0.6750 - val_loss: 1.1548 - learning_rate: 3.9063e-06\n",
      "Epoch 238/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8890 - loss: 0.7852 - val_accuracy: 0.6750 - val_loss: 1.1543 - learning_rate: 3.9063e-06\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9062 - loss: 0.7411\n",
      "Epoch 239: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8925 - loss: 0.7691 - val_accuracy: 0.6750 - val_loss: 1.1540 - learning_rate: 3.9063e-06\n",
      "Epoch 240/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9049 - loss: 0.7057 - val_accuracy: 0.6750 - val_loss: 1.1533 - learning_rate: 1.9531e-06\n",
      "Epoch 241/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8627 - loss: 0.8314 - val_accuracy: 0.6750 - val_loss: 1.1530 - learning_rate: 1.9531e-06\n",
      "Epoch 242/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8634 - loss: 0.8442 - val_accuracy: 0.6750 - val_loss: 1.1532 - learning_rate: 1.9531e-06\n",
      "Epoch 243/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9176 - loss: 0.7282 - val_accuracy: 0.6750 - val_loss: 1.1532 - learning_rate: 1.9531e-06\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9062 - loss: 0.7258\n",
      "Epoch 244: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9041 - loss: 0.7566 - val_accuracy: 0.6750 - val_loss: 1.1535 - learning_rate: 1.9531e-06\n",
      "Epoch 245/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9179 - loss: 0.7276 - val_accuracy: 0.6750 - val_loss: 1.1535 - learning_rate: 9.7656e-07\n",
      "Epoch 246/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9154 - loss: 0.7184 - val_accuracy: 0.6750 - val_loss: 1.1531 - learning_rate: 9.7656e-07\n",
      "Epoch 247/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9353 - loss: 0.6843 - val_accuracy: 0.6750 - val_loss: 1.1534 - learning_rate: 9.7656e-07\n",
      "Epoch 248/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9119 - loss: 0.7720 - val_accuracy: 0.6750 - val_loss: 1.1532 - learning_rate: 9.7656e-07\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8438 - loss: 0.8619\n",
      "Epoch 249: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8601 - loss: 0.8236 - val_accuracy: 0.6750 - val_loss: 1.1531 - learning_rate: 9.7656e-07\n",
      "Epoch 250/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9058 - loss: 0.7742 - val_accuracy: 0.6750 - val_loss: 1.1535 - learning_rate: 4.8828e-07\n",
      "Epoch 251/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9434 - loss: 0.6717 - val_accuracy: 0.6750 - val_loss: 1.1529 - learning_rate: 4.8828e-07\n",
      "Epoch 252/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8917 - loss: 0.7973 - val_accuracy: 0.6750 - val_loss: 1.1527 - learning_rate: 4.8828e-07\n",
      "Epoch 253/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9090 - loss: 0.7850 - val_accuracy: 0.6750 - val_loss: 1.1523 - learning_rate: 4.8828e-07\n",
      "Epoch 254/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8967 - loss: 0.7355 - val_accuracy: 0.6750 - val_loss: 1.1527 - learning_rate: 4.8828e-07\n",
      "Epoch 255/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9439 - loss: 0.6752 - val_accuracy: 0.6750 - val_loss: 1.1529 - learning_rate: 4.8828e-07\n",
      "Epoch 256/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8289 - loss: 0.8853 - val_accuracy: 0.6750 - val_loss: 1.1530 - learning_rate: 4.8828e-07\n",
      "Epoch 257/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9460 - loss: 0.7298 - val_accuracy: 0.6750 - val_loss: 1.1529 - learning_rate: 4.8828e-07\n",
      "Epoch 258/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8855 - loss: 0.8510 - val_accuracy: 0.6750 - val_loss: 1.1522 - learning_rate: 4.8828e-07\n",
      "Epoch 259/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9154 - loss: 0.8075 - val_accuracy: 0.6750 - val_loss: 1.1519 - learning_rate: 4.8828e-07\n",
      "Epoch 260/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9030 - loss: 0.7526 - val_accuracy: 0.6750 - val_loss: 1.1517 - learning_rate: 4.8828e-07\n",
      "Epoch 261/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8951 - loss: 0.7395 - val_accuracy: 0.6750 - val_loss: 1.1513 - learning_rate: 4.8828e-07\n",
      "Epoch 262/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9633 - loss: 0.6956 - val_accuracy: 0.6750 - val_loss: 1.1516 - learning_rate: 4.8828e-07\n",
      "Epoch 263/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9283 - loss: 0.7717 - val_accuracy: 0.6750 - val_loss: 1.1517 - learning_rate: 4.8828e-07\n",
      "Epoch 264/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8726 - loss: 0.8163 - val_accuracy: 0.6750 - val_loss: 1.1521 - learning_rate: 4.8828e-07\n",
      "Epoch 265/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8968 - loss: 0.7707 - val_accuracy: 0.6750 - val_loss: 1.1518 - learning_rate: 4.8828e-07\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9688 - loss: 0.7585\n",
      "Epoch 266: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9348 - loss: 0.7478 - val_accuracy: 0.6750 - val_loss: 1.1521 - learning_rate: 4.8828e-07\n",
      "Epoch 267/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8989 - loss: 0.8158 - val_accuracy: 0.6750 - val_loss: 1.1521 - learning_rate: 2.4414e-07\n",
      "Epoch 268/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9474 - loss: 0.7240 - val_accuracy: 0.6750 - val_loss: 1.1516 - learning_rate: 2.4414e-07\n",
      "Epoch 269/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9237 - loss: 0.7201 - val_accuracy: 0.6750 - val_loss: 1.1515 - learning_rate: 2.4414e-07\n",
      "Epoch 270/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9099 - loss: 0.7720 - val_accuracy: 0.6750 - val_loss: 1.1512 - learning_rate: 2.4414e-07\n",
      "Epoch 271/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9150 - loss: 0.7691 - val_accuracy: 0.6750 - val_loss: 1.1512 - learning_rate: 2.4414e-07\n",
      "Epoch 272/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9054 - loss: 0.7784 - val_accuracy: 0.6750 - val_loss: 1.1513 - learning_rate: 2.4414e-07\n",
      "Epoch 273/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8942 - loss: 0.7899 - val_accuracy: 0.6750 - val_loss: 1.1517 - learning_rate: 2.4414e-07\n",
      "Epoch 274/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9443 - loss: 0.7002 - val_accuracy: 0.6750 - val_loss: 1.1517 - learning_rate: 2.4414e-07\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9688 - loss: 0.7025\n",
      "Epoch 275: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9310 - loss: 0.7438 - val_accuracy: 0.6750 - val_loss: 1.1519 - learning_rate: 2.4414e-07\n",
      "Epoch 276/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9124 - loss: 0.7625 - val_accuracy: 0.6750 - val_loss: 1.1516 - learning_rate: 1.2207e-07\n",
      "Epoch 277/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9339 - loss: 0.6861 - val_accuracy: 0.6750 - val_loss: 1.1507 - learning_rate: 1.2207e-07\n",
      "Epoch 278/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8833 - loss: 0.7977 - val_accuracy: 0.6750 - val_loss: 1.1515 - learning_rate: 1.2207e-07\n",
      "Epoch 279/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9423 - loss: 0.6945 - val_accuracy: 0.6750 - val_loss: 1.1509 - learning_rate: 1.2207e-07\n",
      "Epoch 280/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9388 - loss: 0.6958 - val_accuracy: 0.6750 - val_loss: 1.1508 - learning_rate: 1.2207e-07\n",
      "Epoch 281/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9145 - loss: 0.7432 - val_accuracy: 0.6750 - val_loss: 1.1514 - learning_rate: 1.2207e-07\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.9375 - loss: 0.7577\n",
      "Epoch 282: ReduceLROnPlateau reducing learning rate to 1e-07.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9521 - loss: 0.7284 - val_accuracy: 0.6750 - val_loss: 1.1514 - learning_rate: 1.2207e-07\n",
      "Epoch 283/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9469 - loss: 0.6992 - val_accuracy: 0.6750 - val_loss: 1.1520 - learning_rate: 1.0000e-07\n",
      "Epoch 284/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9517 - loss: 0.6706 - val_accuracy: 0.6750 - val_loss: 1.1522 - learning_rate: 1.0000e-07\n",
      "Epoch 285/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9245 - loss: 0.7589 - val_accuracy: 0.6750 - val_loss: 1.1518 - learning_rate: 1.0000e-07\n",
      "Epoch 286/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9205 - loss: 0.7476 - val_accuracy: 0.6750 - val_loss: 1.1512 - learning_rate: 1.0000e-07\n",
      "Epoch 287/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9149 - loss: 0.7307 - val_accuracy: 0.6750 - val_loss: 1.1512 - learning_rate: 1.0000e-07\n",
      "Epoch 288/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9115 - loss: 0.7975 - val_accuracy: 0.6750 - val_loss: 1.1515 - learning_rate: 1.0000e-07\n",
      "Epoch 289/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9171 - loss: 0.7443 - val_accuracy: 0.6750 - val_loss: 1.1522 - learning_rate: 1.0000e-07\n",
      "Epoch 290/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8821 - loss: 0.7578 - val_accuracy: 0.6750 - val_loss: 1.1523 - learning_rate: 1.0000e-07\n",
      "Epoch 291/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9444 - loss: 0.7210 - val_accuracy: 0.6750 - val_loss: 1.1522 - learning_rate: 1.0000e-07\n",
      "Epoch 292/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9257 - loss: 0.7188 - val_accuracy: 0.6750 - val_loss: 1.1519 - learning_rate: 1.0000e-07\n",
      "Epoch 293/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8963 - loss: 0.7823 - val_accuracy: 0.6750 - val_loss: 1.1516 - learning_rate: 1.0000e-07\n",
      "Epoch 294/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9076 - loss: 0.8513 - val_accuracy: 0.6750 - val_loss: 1.1519 - learning_rate: 1.0000e-07\n",
      "Epoch 295/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9360 - loss: 0.6714 - val_accuracy: 0.6750 - val_loss: 1.1518 - learning_rate: 1.0000e-07\n",
      "Epoch 296/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9378 - loss: 0.7210 - val_accuracy: 0.6750 - val_loss: 1.1518 - learning_rate: 1.0000e-07\n",
      "Epoch 297/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9080 - loss: 0.7456 - val_accuracy: 0.6750 - val_loss: 1.1516 - learning_rate: 1.0000e-07\n",
      "Epoch 298/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9033 - loss: 0.7507 - val_accuracy: 0.6750 - val_loss: 1.1521 - learning_rate: 1.0000e-07\n",
      "Epoch 299/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8820 - loss: 0.7916 - val_accuracy: 0.6750 - val_loss: 1.1524 - learning_rate: 1.0000e-07\n",
      "Epoch 300/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8535 - loss: 0.7904 - val_accuracy: 0.6750 - val_loss: 1.1524 - learning_rate: 1.0000e-07\n",
      "Epoch 301/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9499 - loss: 0.6718 - val_accuracy: 0.6750 - val_loss: 1.1525 - learning_rate: 1.0000e-07\n",
      "Epoch 302/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9547 - loss: 0.6993 - val_accuracy: 0.6750 - val_loss: 1.1522 - learning_rate: 1.0000e-07\n",
      "Epoch 303/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9011 - loss: 0.7995 - val_accuracy: 0.6750 - val_loss: 1.1523 - learning_rate: 1.0000e-07\n",
      "Epoch 304/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9314 - loss: 0.7819 - val_accuracy: 0.6750 - val_loss: 1.1521 - learning_rate: 1.0000e-07\n",
      "Epoch 305/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9555 - loss: 0.6917 - val_accuracy: 0.6750 - val_loss: 1.1521 - learning_rate: 1.0000e-07\n",
      "Epoch 306/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8902 - loss: 0.8274 - val_accuracy: 0.6750 - val_loss: 1.1522 - learning_rate: 1.0000e-07\n",
      "Epoch 307/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9434 - loss: 0.7230 - val_accuracy: 0.6750 - val_loss: 1.1522 - learning_rate: 1.0000e-07\n",
      "Epoch 308/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9050 - loss: 0.7533 - val_accuracy: 0.6750 - val_loss: 1.1514 - learning_rate: 1.0000e-07\n",
      "Epoch 309/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8638 - loss: 0.8402 - val_accuracy: 0.6750 - val_loss: 1.1517 - learning_rate: 1.0000e-07\n",
      "Epoch 310/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8899 - loss: 0.7448 - val_accuracy: 0.6750 - val_loss: 1.1518 - learning_rate: 1.0000e-07\n",
      "Epoch 311/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9849 - loss: 0.6860 - val_accuracy: 0.6750 - val_loss: 1.1517 - learning_rate: 1.0000e-07\n",
      "Epoch 312/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9504 - loss: 0.6992 - val_accuracy: 0.6750 - val_loss: 1.1519 - learning_rate: 1.0000e-07\n",
      "Epoch 313/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9236 - loss: 0.7663 - val_accuracy: 0.6750 - val_loss: 1.1521 - learning_rate: 1.0000e-07\n",
      "Epoch 314/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8928 - loss: 0.7854 - val_accuracy: 0.6750 - val_loss: 1.1527 - learning_rate: 1.0000e-07\n",
      "Epoch 315/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9197 - loss: 0.7328 - val_accuracy: 0.6750 - val_loss: 1.1527 - learning_rate: 1.0000e-07\n",
      "Epoch 316/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8497 - loss: 0.8648 - val_accuracy: 0.6750 - val_loss: 1.1522 - learning_rate: 1.0000e-07\n",
      "Epoch 317/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9102 - loss: 0.7180 - val_accuracy: 0.6750 - val_loss: 1.1522 - learning_rate: 1.0000e-07\n",
      "Epoch 318/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9375 - loss: 0.7231 - val_accuracy: 0.6750 - val_loss: 1.1519 - learning_rate: 1.0000e-07\n",
      "Epoch 319/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8735 - loss: 0.8278 - val_accuracy: 0.6750 - val_loss: 1.1520 - learning_rate: 1.0000e-07\n",
      "Epoch 320/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9279 - loss: 0.7540 - val_accuracy: 0.6750 - val_loss: 1.1516 - learning_rate: 1.0000e-07\n",
      "Epoch 321/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9487 - loss: 0.7385 - val_accuracy: 0.6750 - val_loss: 1.1517 - learning_rate: 1.0000e-07\n",
      "Epoch 322/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8872 - loss: 0.8009 - val_accuracy: 0.6750 - val_loss: 1.1518 - learning_rate: 1.0000e-07\n",
      "Epoch 323/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9248 - loss: 0.7480 - val_accuracy: 0.6750 - val_loss: 1.1523 - learning_rate: 1.0000e-07\n",
      "Epoch 324/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9120 - loss: 0.7708 - val_accuracy: 0.6750 - val_loss: 1.1519 - learning_rate: 1.0000e-07\n",
      "Epoch 325/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9219 - loss: 0.7553 - val_accuracy: 0.6750 - val_loss: 1.1528 - learning_rate: 1.0000e-07\n",
      "Epoch 326/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8946 - loss: 0.7211 - val_accuracy: 0.6750 - val_loss: 1.1536 - learning_rate: 1.0000e-07\n",
      "Epoch 327/1000\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9288 - loss: 0.7597 - val_accuracy: 0.6750 - val_loss: 1.1542 - learning_rate: 1.0000e-07\n",
      "Best Validation Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "''' ANN Model '''\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Ensuring that target labels are properly encoded\n",
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "# Defining Tensorflow Callbacks & Optimizer\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)  # Stop early if validation loss doesn't improve\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1, min_lr=1e-6)  # Reduce Learning Rate as validation loss plateaus for faster training\n",
    "rmsprop_optimizier = tf.keras.optimizers.RMSprop(learning_rate=.001)\n",
    "adam_optimizier = tf.keras.optimizers.Adam(learning_rate=.001)\n",
    "\n",
    "# Creating the model\n",
    "ANN_model2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.InputLayer(shape=(65,)),  # Input Layer - Each Feature to a Node\n",
    "    tf.keras.layers.Dense(65, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(.05)),  # First Dense Layer\n",
    "    tf.keras.layers.BatchNormalization(),  # Normalize layer\n",
    "    tf.keras.layers.Dropout(.5),  # Drop out 50% of data to mitigate overfitting\n",
    "    tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(.03)),  # Second Dense Layer\n",
    "    tf.keras.layers.BatchNormalization(),  # Normalize layer\n",
    "    tf.keras.layers.Dropout(.35),  # Drop out 35% of data to mitigate overfitting\n",
    "    #tf.keras.layers.Dense(30, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(.03)),  # Third Dense Layer\n",
    "    tf.keras.layers.Dense(20, activation='softmax'),  # Last Dense Layer, classify as yes or no\n",
    "])\n",
    "\n",
    "ANN_model2.compile(optimizer=adam_optimizier, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history = ANN_model2.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), epochs=1000, batch_size=32, \n",
    "               verbose=1, callbacks=[early_stopping, lr_scheduler])\n",
    "\n",
    "# Printing the best validation accuracy\n",
    "best_val_accuracy = max(history.history['val_accuracy'])\n",
    "print(f\"Best Validation Accuracy: {best_val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_38\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_38\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_122 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,290</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">260</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_123 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_124 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_122 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)             │         \u001b[38;5;34m4,290\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_30          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)             │           \u001b[38;5;34m260\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_51 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_123 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_52 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_124 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m660\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,964</span> (85.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,964\u001b[0m (85.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,256</span> (28.34 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,256\u001b[0m (28.34 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">194</span> (776.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m194\u001b[0m (776.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,514</span> (56.70 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m14,514\u001b[0m (56.70 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#ANN_model2.save('875-valaccuracy-1.keras')\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_ANN_model = load_model('875-valaccuracy-1.keras')\n",
    "loaded_ANN_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Best Essemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: RandomForestClassifier(max_depth=15, min_samples_split=4, n_jobs=-1,\n",
      "                       random_state=42)\n",
      "Best Score: 0.6473790322580645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Output:\\n\\n'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Making Random Forest Ensemble Method using previous data '''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Creating Classifier\n",
    "rand_forest_model_2 = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "\n",
    "# Finding optimal parameters using GridSearchCV\n",
    "params = {\n",
    "    'n_estimators': [i for i in range(100, 400, 100)],  # Tuned as needed\n",
    "    'max_depth': [i for i in range(15, 30, 5)],\n",
    "    'min_samples_split': [4, 5],\n",
    "}\n",
    "grid_search_rf2 = GridSearchCV(rand_forest_model_2, params, cv=5, n_jobs=-1)\n",
    "grid_search_rf2.fit(x_train, y_train)\n",
    "print(f\"Best Parameters: {grid_search_rf2.best_estimator_}\")\n",
    "print(f\"Best Score: {grid_search_rf2.best_score_}\")\n",
    "\n",
    "''' Output:\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n",
      "Best XGBoost Parameters: {'colsample_bytree': 0.9999999999999999, 'learning_rate': 0.1, 'max_depth': 2, 'n_estimators': 180, 'subsample': 0.7999999999999999} with score 0.6025641025641026\n",
      "Independent Test Accuracy: 0.525\n"
     ]
    }
   ],
   "source": [
    "''' Boosting Ensemble Method '''\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb_model = XGBClassifier(n_jobs=-1, random_state=42)\n",
    "params_xgb = {\n",
    "    'n_estimators': [i for i in range(170, 200, 10)],\n",
    "    'max_depth': [i for i in range(1, 5)],\n",
    "    'learning_rate': [0.1],\n",
    "    'subsample': [i for i in np.arange(.7, .9, .1)],\n",
    "    'colsample_bytree': [i for i in np.arange(.7, 1.5, .1)]\n",
    "}\n",
    "\n",
    "# Using grid search to test parameters\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=params_xgb, cv=3, verbose=1, n_jobs=-1)\n",
    "grid_search_xgb.fit(x_train, y_train)\n",
    "print(f\"Best XGBoost Parameters: {grid_search_xgb.best_params_} with score {grid_search_xgb.best_score_}\")\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n",
    "print(f\"Independent Test Accuracy: {accuracy_score(y_test, best_xgb_model.predict(x_test))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Ensemble of ANN '''\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model():\n",
    "    # Building the same model as previously\n",
    "    model = tf.keras.models.sequential([\n",
    "        tf.keras.layers.InputLayer(shape=(65,)),  # Input Layer - Each Feature to a Node\n",
    "        tf.keras.layers.Dense(65, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(.05)),  # First Dense Layer\n",
    "        tf.keras.layers.BatchNormalization(),  # Normalize layer\n",
    "        tf.keras.layers.Dropout(.5),  # Drop out 50% of data to mitigate overfitting\n",
    "        tf.keras.layers.Dense(32, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(.03)),  # Second Dense Layer\n",
    "        tf.keras.layers.BatchNormalization(),  # Normalize layer\n",
    "        tf.keras.layers.Dropout(.35),  # Drop out 35% of data to mitigate overfitting\n",
    "        #tf.keras.layers.Dense(30, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(.03)),  # Third Dense Layer\n",
    "        tf.keras.layers.Dense(20, activation='softmax'),  # Last Dense Layer\n",
    "        ])\n",
    "    return model\n",
    "\n",
    "# Training models\n",
    "n_models = 10\n",
    "models = []\n",
    "\n",
    "for i in range(n_models):\n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
